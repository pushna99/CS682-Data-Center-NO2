{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS682_Project-Pushna_Version 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMX5LspQgdnFsimhAErU/fQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pushna99/CS682-Data-Center-NO2/blob/main/CS682_Project_Pushna_Version_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eC_hY2qkEunz"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from geopy.geocoders import Nominatim\n",
        "from geopy import distance\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "# Get the contents of NASA Timeseries files through URL\n",
        "!wget https://so2.gsfc.nasa.gov/no2/pix/time_series/OMNO2_Timeseries_AllCities.csv -q\n",
        "data=pd.read_csv('OMNO2_Timeseries_AllCities.csv',index_col=False, on_bad_lines='skip',skiprows=7)\n",
        "df = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum_med = df.groupby('City')['Median'].mean()\n",
        "print(sum_med)\n",
        "\n",
        "with open('OMNO2_Timeseries_AllCities.csv','r') as f_in:\n",
        "    f = csv.reader(f_in)\n",
        "    rows=df.groupby(['City','Country','LonCenter','LatCenter']).agg({'Median': ['mean']})\n",
        "    rows.columns = ['Average NO2']\n",
        "    rows = rows.reset_index()\n",
        "\n",
        "geolocator = Nominatim(user_agent='myapplication')\n",
        "for index, row in rows.iterrows():\n",
        "  #Get latitude and longitude using city and state code (for US cities)/ country name \n",
        "  location = geolocator.geocode(row[0]+\",\"+row[1],timeout=1000)\n",
        "  if not location == None:\n",
        "    rows.loc[index,\"LatCenter\"]=location.latitude\n",
        "    rows.loc[index,\"LonCenter\"]=location.longitude\n",
        "\n",
        "\n",
        "#Authorize access to google sheets and fetch the nasa-cities file into a dataframe\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "nasa_cities_worksheet = gc.open('nasa-cities').sheet1\n",
        "rows = nasa_cities_worksheet.get_all_values()\n",
        "nasa_cities = pd.DataFrame.from_records(rows)\n",
        "nasa_cities.columns = nasa_cities.iloc[0]\n",
        "nasa_cities = nasa_cities[1:]\n",
        "nasa_cities = nasa_cities.rename(columns={'City': 'City Name','LonCenter':'Longitude','LatCenter':'Latitude'})\n",
        "nasa_cities.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrvqqjCpE0kD",
        "outputId": "389b9c2e-5e00-4a6b-fefe-2fdf3a8cc2a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "City\n",
            "Aberdeen     -0.241590\n",
            "Abidjan      -0.289164\n",
            "AbuDhabi      2.574397\n",
            "Abuja         1.005829\n",
            "Accra        -1.289991\n",
            "               ...    \n",
            "Yangoon     -13.736218\n",
            "Yaounde      -0.751641\n",
            "Yerevan       1.201822\n",
            "Zhengzhou     6.617612\n",
            "Zurich        1.628643\n",
            "Name: Median, Length: 316, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read contents of lat-lon file\n",
        "latlong = gc.open('lat-lon').sheet1\n",
        "rows = latlong.get_all_values()\n",
        "dfll = pd.DataFrame.from_records(rows)\n",
        "# Convert first column to header\n",
        "dfll.columns = dfll.iloc[0]\n",
        "dfll = dfll[1:]\n",
        "\n",
        "#read contents of input file containing customer cities\n",
        "cityname = gc.open('input').sheet1\n",
        "rows = cityname.get_all_values()\n",
        "dfcity = pd.DataFrame.from_records(rows)\n",
        "# Convert first column to header\n",
        "dfcity.columns = dfcity.iloc[0]\n",
        "dfcity = dfcity[1:]\n",
        "\n",
        "#Add two new columns \"Latitude\" and \"Longitude\"\n",
        "dfcity[\"Latitude\"] = pd.NaT\n",
        "dfcity[\"Longitude\"] = pd.NaT\n",
        "geolocator = Nominatim(user_agent='myapplication')\n",
        "for index, row in dfcity.iterrows():\n",
        "  #Get latitude and longitude using city and state code (for US cities)/ country name \n",
        "  location = geolocator.geocode(row[0]+\",\"+row[1],timeout=1000)\n",
        "  if not location == None:\n",
        "    dfcity.loc[index,\"Latitude\"]=location.latitude\n",
        "    dfcity.loc[index,\"Longitude\"]=location.longitude\n",
        "\n",
        "#Drop NaT values and update the lat-lon file\n",
        "dfcity=dfcity.dropna()\n",
        "dfcity.update([dfcity.columns.values.tolist()] + dfcity.values.tolist())\n",
        "\n",
        "customer_cities = pd.concat([dfcity,dfll], axis = 0).drop_duplicates().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "ezYeFdUUE2k3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nasa_cities = nasa_cities.apply(pd.to_numeric, errors='ignore')\n",
        "customer_cities = customer_cities.apply(pd.to_numeric, errors='ignore')\n",
        "#NO2data = pd.merge(customer_cities,nasa_cities , on=['Longitude','Latitude'])\n",
        "customer_cities[\"Average NO2\"] = pd.NaT\n",
        "\n",
        "# Check the nearest city based on latitude and longitude values\n",
        "for index, row in customer_cities.iterrows():\n",
        "  min_distance=float('inf')\n",
        "  for nindex, nrow in nasa_cities.iterrows():\n",
        "    if(distance.distance((row['Latitude'],row['Longitude']), (nrow['Latitude'],nrow['Longitude'])).miles < min_distance):\n",
        "      min_distance = distance.distance((row['Latitude'],row['Longitude']), (nrow['Latitude'],nrow['Longitude'])).miles\n",
        "      min_index = nindex\n",
        "  customer_cities.loc[index,'Average NO2'] = nasa_cities['Average NO2'].values[min_index]"
      ],
      "metadata": {
        "id": "z9-TrkgxE698"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a new Average NO2 data in the output folder\n",
        "average_no2_data = gc.create('average_no2_data').sheet1\n",
        "average_no2_data.update([customer_cities.columns.values.tolist()] + customer_cities.values.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4MdZrkgE9H7",
        "outputId": "cd1cf673-56f2-4fef-ddc8-c783af9b688f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1ThRkPX9sAHfWlWcxZPlPNUyiaJ3tUnOtEmuKbRxqlzg',\n",
              " 'updatedCells': 535,\n",
              " 'updatedColumns': 5,\n",
              " 'updatedRange': 'Sheet1!A1:E107',\n",
              " 'updatedRows': 107}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}